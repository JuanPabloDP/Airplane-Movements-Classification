{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6de5104f",
   "metadata": {},
   "source": [
    "# Evaluación de algoritmos de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d5851e",
   "metadata": {},
   "source": [
    "Seleccione cinco modelos de clasificación no vistos en clase, y evalúelos con sus conjuntos de datos. Calcule tanto la exactitud, la precisión por clase y la sensibilidad por clase para cada uno de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb704c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26d18e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"Data1.txt\")\n",
    "x = data[:, 1:]\n",
    "y = data[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7010703",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28dace40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.87      0.93        60\n",
      "         2.0       1.00      0.98      0.99        60\n",
      "         3.0       1.00      0.92      0.96        60\n",
      "         4.0       1.00      0.95      0.97        60\n",
      "         5.0       0.95      0.98      0.97        60\n",
      "         6.0       1.00      0.98      0.99        60\n",
      "         7.0       0.90      1.00      0.94        60\n",
      "         8.0       0.97      0.98      0.98        60\n",
      "         9.0       0.88      1.00      0.94        60\n",
      "\n",
      "    accuracy                           0.96       540\n",
      "   macro avg       0.97      0.96      0.96       540\n",
      "weighted avg       0.97      0.96      0.96       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stratified Shuffle Split cross-validation\n",
    "sss = StratifiedShuffleSplit(\n",
    "        n_splits=5,\n",
    "        train_size=0.8,\n",
    "        random_state=1234\n",
    "    ) \n",
    "\n",
    "cv_y_test = [] #Etiquetas verdaderas \n",
    "cv_y_pred = [] #Etiquetas predecidas \n",
    "\n",
    "for train_index, test_index in sss.split(x, y): \n",
    "\n",
    "    # Training phase\n",
    "    x_train = x[train_index, :] \n",
    "    y_train = y[train_index] \n",
    "\n",
    "    clf_cv = RandomForestClassifier(max_depth=10, random_state=1234)\n",
    "    # The maximum depth of the tree. \n",
    "    clf_cv.fit(x_train, y_train)\n",
    "\n",
    "    # Test phase\n",
    "    x_test = x[test_index, :]\n",
    "    y_test = y[test_index]    \n",
    "    y_pred = clf_cv.predict(x_test)\n",
    "\n",
    "    # Concatenate results of evaluation\n",
    "    cv_y_test.append(y_test)\n",
    "    cv_y_pred.append(y_pred)   \n",
    "\n",
    "# Model performance\n",
    "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770e0e57",
   "metadata": {},
   "source": [
    "# Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e1b70df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juanp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\juanp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\juanp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\juanp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\juanp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.75      0.25      0.38        60\n",
      "         2.0       0.32      0.58      0.42        60\n",
      "         3.0       0.16      0.40      0.23        60\n",
      "         4.0       0.00      0.00      0.00        60\n",
      "         5.0       0.15      0.40      0.22        60\n",
      "         6.0       1.00      0.18      0.31        60\n",
      "         7.0       0.00      0.00      0.00        60\n",
      "         8.0       0.00      0.00      0.00        60\n",
      "         9.0       0.54      0.88      0.67        60\n",
      "\n",
      "    accuracy                           0.30       540\n",
      "   macro avg       0.33      0.30      0.25       540\n",
      "weighted avg       0.33      0.30      0.25       540\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juanp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\juanp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\juanp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Stratified Shuffle Split cross-validation\n",
    "sss = StratifiedShuffleSplit(\n",
    "        n_splits=5,\n",
    "        train_size=0.8,\n",
    "        random_state=1234\n",
    "    ) \n",
    "\n",
    "cv_y_test = [] #Etiquetas verdaderas \n",
    "cv_y_pred = [] #Etiquetas predecidas \n",
    "\n",
    "for train_index, test_index in sss.split(x, y): \n",
    "\n",
    "    # Training phase\n",
    "    x_train = x[train_index, :] \n",
    "    y_train = y[train_index] \n",
    "\n",
    "    clf_cv = AdaBoostClassifier(n_estimators=100, random_state=1234)\n",
    "    # The maximum number of estimators at which boosting is terminated. \n",
    "    # In case of perfect fit, the learning procedure is stopped early. \n",
    "    # Values must be in the range [1, inf).\n",
    "    clf_cv.fit(x_train, y_train)\n",
    "\n",
    "    # Test phase\n",
    "    x_test = x[test_index, :]\n",
    "    y_test = y[test_index]    \n",
    "    y_pred = clf_cv.predict(x_test)\n",
    "\n",
    "    # Concatenate results of evaluation\n",
    "    cv_y_test.append(y_test)\n",
    "    cv_y_pred.append(y_pred)   \n",
    "\n",
    "# Model performance\n",
    "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be64b6",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c68faa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.88      0.94        60\n",
      "         2.0       1.00      0.98      0.99        60\n",
      "         3.0       1.00      0.92      0.96        60\n",
      "         4.0       0.94      0.97      0.95        60\n",
      "         5.0       0.89      0.92      0.90        60\n",
      "         6.0       1.00      0.98      0.99        60\n",
      "         7.0       0.95      0.97      0.96        60\n",
      "         8.0       0.95      0.95      0.95        60\n",
      "         9.0       0.86      0.98      0.91        60\n",
      "\n",
      "    accuracy                           0.95       540\n",
      "   macro avg       0.95      0.95      0.95       540\n",
      "weighted avg       0.95      0.95      0.95       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stratified Shuffle Split cross-validation\n",
    "sss = StratifiedShuffleSplit(\n",
    "        n_splits=5,\n",
    "        train_size=0.8,\n",
    "        random_state=1234\n",
    "    ) \n",
    "\n",
    "cv_y_test = [] #Etiquetas verdaderas \n",
    "cv_y_pred = [] #Etiquetas predecidas \n",
    "\n",
    "for train_index, test_index in sss.split(x, y): \n",
    "\n",
    "    # Training phase\n",
    "    x_train = x[train_index, :] \n",
    "    y_train = y[train_index] \n",
    "\n",
    "    clf_cv = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=3, random_state=0)\n",
    "    # Learning rate shrinks the contribution of each tree by learning_rate. \n",
    "    # There is a trade-off between learning_rate and n_estimators. \n",
    "    # Values must be in the range [0.0, inf).\n",
    "\n",
    "    # Maximum depth of the individual regression estimators. \n",
    "    # The maximum depth limits the number of nodes in the tree. \n",
    "    # Tune this parameter for best performance; the best value depends on the interaction of the input variables.\n",
    "    \n",
    "    clf_cv.fit(x_train, y_train)\n",
    "\n",
    "    # Test phase\n",
    "    x_test = x[test_index, :]\n",
    "    y_test = y[test_index]    \n",
    "    y_pred = clf_cv.predict(x_test)\n",
    "\n",
    "    # Concatenate results of evaluation\n",
    "    cv_y_test.append(y_test)\n",
    "    cv_y_pred.append(y_pred)   \n",
    "\n",
    "# Model performance\n",
    "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
